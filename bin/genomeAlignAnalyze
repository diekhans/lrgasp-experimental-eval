#!/usr/bin/env python3

from collections import defaultdict
import argparse
import pysam
import pipettor
from collections import namedtuple
from pycbio.sys import fileOps
from pycbio.hgdata.bed import BedTable
from pycbio.hgdata.cigar import Cigar
from pycbio.tsv import TsvReader

def parseArgs():
    desc = """count the number of reads that validated an amplicon intron chain. """
    parser = argparse.ArgumentParser(description=desc)
    parser.add_argument("--target",
                        help="""only analyze this target name""")
    parser.add_argument("--maxIndelBases", type=int, default=None,
                        help="""maximum indel bases filter""")
    parser.add_argument("--supportBam",
                        help="""output BAMs of those supporting the chain""")
    parser.add_argument("jujuIsoformsTsv",
                        help="""isoforms.tsv with targets and transcripts""")
    parser.add_argument("targetsBed",
                        help="""bed with targets transcript with amplicons in thick """)
    parser.add_argument("readsBam",
                        help="""genome BAM""")
    parser.add_argument("statsTsv",
                        help="""output statistics to this file""")
    opts = parser.parse_args()
    opts.filters = Filters(target=opts.target,
                           maxIndelBases=opts.maxIndelBases)

    return opts

class Filters(namedtuple("Filters", ("target",
                                     "maxIndelBases"))):
    __slots__ = ()


def loadJuJuDesigns(jujuIsoformsTsv):
    # target_id primer_id pri track transcript_id amplicon_coords amplicon_len amplicon_exons amplicon
    designs = defaultdict(list)
    for row in TsvReader(jujuIsoformsTsv, typeMap={"pri": int}):
        designs[row.target_id].append(row)
    designs.default_factory = None
    return designs

def getThickIntronChain(bed):
    chain = []
    prevBlk = None
    for blk in bed.blocks:
        if (blk.start < bed.thickEnd) and (blk.end > bed.thickStart):
            if prevBlk is not None:
                chain.append((prevBlk.end, blk.start))
            prevBlk = blk
    return tuple(chain)

def getReadChain(aln):
    # don't allow indels to be adjacent to a intron like the ALG6 U12 example
    # 65M 4013N 6D 58M
    tNext = aln.reference_start
    chain = []
    cigar = Cigar(aln.cigarstring)
    for i in range(len(cigar)):
        run = cigar[i]
        if (run.intron and not (cigar[i - 1].tinsert or cigar[i + 1].tinsert or
                                cigar[i - 1].tdelete or cigar[i + 1].tdelete)):
            chain.append((tNext, tNext + run.count))
        if run.consumesTarget:
            tNext += run.count
    return tuple(chain)

def filterAlign(aln, filters):
    if filters.maxIndelBases is None:
        return True
    baseCnts, blkCnts = aln.get_cigar_stats()
    qDelBases = baseCnts[pysam.CDEL]
    tDelBases = baseCnts[pysam.CINS]
    return (qDelBases + tDelBases) <= filters.maxIndelBases

def alnSupports(aln, ampliconChain, filters):
    if not filterAlign(aln, filters):
        return False
    readChain = getReadChain(aln)
    return readChain == ampliconChain

def countSupports(targetsBed, ampliconChain, readsBamFh, filters, supportBamFh):
    supportCnt = 0
    for aln in readsBamFh.fetch(reference=targetsBed.chrom, start=targetsBed.start, end=targetsBed.end):
        if alnSupports(aln, ampliconChain, filters):
            supportCnt += 1
            if supportBamFh is not None:
                supportBamFh.write(aln)
    return supportCnt

def processTargetTrans(tdesign, targetsBedTbl, readsBamFh, filters, statsFh, supportBamFh):
    targetsBeds = targetsBedTbl.getByName(tdesign.transcript_id)
    if len(targetsBeds) == 0:
        raise Exception(f"no target BED found for {tdesign.transcript_id}")
    targetsBed = targetsBeds[0]
    ampliconChain = getThickIntronChain(targetsBed)
    supportCnt = countSupports(targetsBed, ampliconChain, readsBamFh, filters, supportBamFh)
    fileOps.prRowv(statsFh, tdesign.target_id, tdesign.transcript_id, supportCnt)


def processTarget(targetId, designs, targetsBedTbl, readsBamFh, filters, statsFh, supportBamFh):
    for tdesign in designs[targetId]:
        if tdesign.pri == 1:
            processTargetTrans(tdesign, targetsBedTbl, readsBamFh, filters, statsFh, supportBamFh)

def processTargets(designs, targetsBedTbl, readsBamFh, filters, statsFh, target=None, supportBamFh=None):
    targets = [filters.target] if filters.target is not None else sorted(designs.keys())
    for targetId in targets:
        try:
            processTarget(targetId, designs, targetsBedTbl, readsBamFh, filters, statsFh, supportBamFh)
        except Exception as ex:
            raise Exception(f"target {targetId} failed") from ex

def genomeAlignAnalyze(jujuIsoformsTsv, targetsBed, readsBam, filters, statsTsv, supportBam):
    designs = loadJuJuDesigns(jujuIsoformsTsv)
    targetsBedTbl = BedTable(targetsBed, nameIdx=True)
    readsBamFh = pysam.AlignmentFile(readsBam)
    supportBamSortFh = None
    supportBamFh = None
    if supportBam is not None:
        supportBamSortFh = pipettor.Popen(["samtools", "sort"], "w", stdout=supportBam)
        supportBamFh = pysam.AlignmentFile(supportBamSortFh, 'wb', template=readsBamFh)

    with open(statsTsv, 'w') as statsFh:
        fileOps.prRowv(statsFh, "target_id", "transcript_id", "chain_supports")
        processTargets(designs, targetsBedTbl, readsBamFh, filters, statsFh, supportBamFh)

    if supportBam is not None:
        supportBamFh.close()
        supportBamSortFh.close()

def main(opts):
    genomeAlignAnalyze(opts.jujuIsoformsTsv, opts.targetsBed, opts.readsBam, opts.filters,
                       opts.statsTsv, opts.supportBam)

main(parseArgs())
