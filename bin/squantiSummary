#!/usr/bin/env python3

import argparse
import pandas as pd
from collections import defaultdict
from pycbio.sys import fileOps
from evalLib import rateFmt, filterToTranscript, splitBySquantiCategory, splitBySupport


def parseArgs():
    desc = """get various stats from the squanti reportst"""
    parser = argparse.ArgumentParser(description=desc)
    parser.add_argument("squantiPaCsv",
                        help="""Presence-absence matrices by UJC""")
    parser.add_argument("evalTsv")
    parser.add_argument("idUjcMapTsv")
    parser.add_argument("reportTsv")
    return parser.parse_args()

def loadSquantiPaCsv(squantiPaCsv):
    paMatrixDf = pd.read_csv(squantiPaCsv)
    paMatrixDf.set_index('TAGS', inplace=True)
    return paMatrixDf

def loadEvalTsv(evalTsv):
    evalDf = pd.read_table(evalTsv)
    transDf = filterToTranscript(evalDf)
    return transDf

def getPipelineColumns(paMatrixDf):
    return [c for c in paMatrixDf.columns if c.startswith("pipeline")]

def countPipelinePredictions(subsetDf):
    predictedByCnt = defaultdict(int)
    pipelineCols = getPipelineColumns(subsetDf)
    predictedCnts = subsetDf[pipelineCols].eq(1).sum(axis=1)
    for pc in predictedCnts:
        predictedByCnt[pc] += 1
    return predictedByCnt

def writePredictions(fh, label, pipelineCnt, matrixDf):
    predictedByCnt = countPipelinePredictions(matrixDf)
    total = sum(predictedByCnt.values())
    cumulativeByCnt = 0
    for cnt in range(1, pipelineCnt + 1):
        if predictedByCnt[cnt] > 0:
            cumulativeByCnt += predictedByCnt[cnt]
            fileOps.prRowv(fh, label, cnt,
                           predictedByCnt[cnt], rateFmt(predictedByCnt[cnt], total),
                           cumulativeByCnt, rateFmt(cumulativeByCnt, total))

def writePredictionsFiltered(fh, label, pipelineCnt, matrixDf, filtLabel, filterDf):
    if filterDf is not None:
        label = filtLabel + label.title()
        matrixDf = matrixDf[matrixDf.transcript.isin(filterDf.transcript)]
    writePredictions(fh, label, pipelineCnt, matrixDf)


def report(paMatrixDf, transDf, idUjcMap, fh):
    fileOps.prRowv(fh, "subset", "pipelineCnts", "transcripts", "rate", "cumulativeCnt", "cumulativeRate")

    pipelineCnt = len(getPipelineColumns(paMatrixDf))
    writePredictions(fh, "all", pipelineCnt, paMatrixDf)

    transUjcDf = pd.merge(transDf, idUjcMap, on="transcript")
    allMatrixDf = pd.merge(paMatrixDf, transUjcDf, left_on="TAGS", right_on="LRGASP_id")

    supportedMatrixDf, unsupportedMatrixDf = splitBySupport(allMatrixDf)
    knownDf, novelDf, ismDf = splitBySquantiCategory(allMatrixDf)

    for filtLabel, filterDf in ((None, None), ("known", knownDf), ("novel", novelDf), ("ism", ismDf)):
        writePredictionsFiltered(fh, "eval", pipelineCnt, allMatrixDf, filtLabel, filterDf)
        writePredictionsFiltered(fh, "supported", pipelineCnt, supportedMatrixDf, filtLabel, filterDf)
        writePredictionsFiltered(fh, "unsupported", pipelineCnt, unsupportedMatrixDf, filtLabel, filterDf)


def squantiSummary(squantiPaCsv, evalTsv, idUjcMapTsv, reportTsv):
    paMatrixDf = loadSquantiPaCsv(squantiPaCsv)
    transDf = loadEvalTsv(evalTsv)
    idUjcMap = pd.read_table(idUjcMapTsv)

    with open(reportTsv, 'w') as fh:
        report(paMatrixDf, transDf, idUjcMap, fh)

def main(opts):
    squantiSummary(opts.squantiPaCsv, opts.evalTsv, opts.idUjcMapTsv, opts.reportTsv)

main(parseArgs())
