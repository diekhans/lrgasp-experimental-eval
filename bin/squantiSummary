#!/usr/bin/env python3

import argparse
import pandas as pd
from collections import defaultdict
from pycbio.sys import fileOps
from evalLib import rateFmt, filterToTranscript, splitBySquantiCategory, splitBySupport, addStructuralCategory

printZeros = False

def parseArgs():
    desc = """get various stats from the squanti reportst"""
    parser = argparse.ArgumentParser(description=desc)
    parser.add_argument("squantiPaCsv",
                        help="""Presence-absence matrices by UJC""")
    parser.add_argument("evalTsv")
    parser.add_argument("idUjcMapTsv")
    parser.add_argument("histoTsv")
    parser.add_argument("statsTsv")
    return parser.parse_args()

def loadSquantiPaCsv(squantiPaCsv):
    paMatrixDf = pd.read_csv(squantiPaCsv)
    paMatrixDf.set_index('TAGS', inplace=True)
    return paMatrixDf

def loadEvalTsv(evalTsv):
    evalDf = pd.read_table(evalTsv)
    transDf = filterToTranscript(evalDf)
    return transDf

def getPipelineColumns(paMatrixDf):
    # wtc11 has pipeline1,pipeline2, ...
    # manatee has illumina1,ONT1,ONT2,...,PB1,PB2,..
    cols = [c for c in paMatrixDf.columns if c.startswith("pipeline")]
    if len(cols) == 0:
        cols = [c for c in paMatrixDf.columns if c.startswith("ONT") or c.startswith("PB")]
    if len(cols) == 0:
        raise Exception("no pipeline columns found")
    return cols

def countPipelinePredictions(matrixDf):
    predictedByCnt = defaultdict(int)
    predictedCnts = matrixDf[getPipelineColumns(matrixDf)].sum(axis=1)
    for pc in predictedCnts:
        predictedByCnt[pc] += 1
    return predictedByCnt

def writePredictionHisto(histoFh, label, subsetLabel, pipelineCnt, matrixDf):
    predictedByCnt = countPipelinePredictions(matrixDf)
    total = sum(predictedByCnt.values())
    cumulativeByCnt = 0
    for cnt in range(1, pipelineCnt + 1):
        if printZeros or (predictedByCnt[cnt] > 0):
            cumulativeByCnt += predictedByCnt[cnt]
            fileOps.prRowv(histoFh, label, subsetLabel, cnt,
                           predictedByCnt[cnt], rateFmt(predictedByCnt[cnt], total),
                           cumulativeByCnt, rateFmt(cumulativeByCnt, total))

def writePredictionStats(statsFh, label, subsetLabel, pipelineCnt, matrixDf):
    predictedCnts = matrixDf[getPipelineColumns(matrixDf)].sum(axis=1)
    if printZeros or (len(predictedCnts) > 0):
        meanPipelineCnt = predictedCnts.mean()
        medianPipelienCnt = predictedCnts.median()
        fileOps.prRowv(statsFh, label, subsetLabel, len(matrixDf),
                       round(meanPipelineCnt, 3),  rateFmt(meanPipelineCnt, pipelineCnt),
                       round(medianPipelienCnt, 3), rateFmt(medianPipelienCnt, pipelineCnt))

def writePredictions(histoFh, statsFh, label, subsetLabel, pipelineCnt, matrixDf, filterDf=None):
    if filterDf is not None:
        matrixDf = matrixDf[matrixDf.structural_category.isin(filterDf.structural_category)]
    writePredictionHisto(histoFh, label, subsetLabel, pipelineCnt, matrixDf)
    writePredictionStats(statsFh, label, subsetLabel, pipelineCnt, matrixDf)


def report(paMatrixDf, transDf, idUjcMap, histoFh, statsFh):
    fileOps.prRowv(histoFh, "set", "subset", "pipelineCnts", "transcripts", "rate",
                   "cumulativeCnt", "cumulativeRate")
    fileOps.prRowv(statsFh, "set", "subset", "transcripts", "meanPipeline", "meanPipelineRate", "medianPipeline", "medianPipelineRate")
    pipelineCnt = len(getPipelineColumns(paMatrixDf))

    # full set
    knownDf, novelDf, ismDf, otherDf = splitBySquantiCategory(paMatrixDf)
    for subsetLabel, filterDf in (("all", None), ("known", knownDf), ("novel", novelDf), ("ism", ismDf), ("other", otherDf)):
        writePredictions(histoFh, statsFh, "all", subsetLabel, pipelineCnt, paMatrixDf, filterDf)

    # PCR set
    transUjcDf = pd.merge(transDf, idUjcMap, on="transcript")
    evaledMatrixDf = pd.merge(paMatrixDf, transUjcDf, left_on="TAGS", right_on="LRGASP_id")
    addStructuralCategory(evaledMatrixDf)
    supportedMatrixDf, unsupportedMatrixDf = splitBySupport(evaledMatrixDf)

    for label, filterDf in (("evaled", None), ("known", knownDf), ("novel", novelDf), ("ism", ismDf)):
        writePredictions(histoFh, statsFh, label, "all", pipelineCnt, evaledMatrixDf, filterDf)
        writePredictions(histoFh, statsFh, label, "supported", pipelineCnt, supportedMatrixDf, filterDf)
        writePredictions(histoFh, statsFh, label, "unsupported", pipelineCnt, unsupportedMatrixDf, filterDf)


def squantiSummary(squantiPaCsv, evalTsv, idUjcMapTsv, histoTsv, statsTsv):
    paMatrixDf = loadSquantiPaCsv(squantiPaCsv)
    transDf = loadEvalTsv(evalTsv)
    idUjcMap = pd.read_table(idUjcMapTsv)

    with open(histoTsv, 'w') as histoFh:
        with open(statsTsv, 'w') as statsFh:
            report(paMatrixDf, transDf, idUjcMap, histoFh, statsFh)

def main(opts):
    squantiSummary(opts.squantiPaCsv, opts.evalTsv, opts.idUjcMapTsv, opts.histoTsv, opts.statsTsv)

main(parseArgs())
