#!/usr/bin/env python3

import argparse
import pandas as pd
from collections import defaultdict
from pycbio.sys import fileOps
from evalLib import rateFmt, filterToTranscript, splitBySqantiCategory, splitBySupport, addStructuralCategory

printZeros = False

def parseArgs():
    desc = """get various stats from the sqanti reportst"""
    parser = argparse.ArgumentParser(description=desc)
    parser.add_argument("--printZeros", action="store_true")
    parser.add_argument("--evalTsv")
    parser.add_argument("--idUjcMapTsv")
    parser.add_argument("--evalPipelineCntTsv",
                        help="write RT-PRC eval info and number of pipelines")
    parser.add_argument("sqantiPaCsv",
                        help="""Presence-absence matrices by UJC""")
    parser.add_argument("histoTsv")
    parser.add_argument("statsTsv")
    opts = parser.parse_args()
    global printZeros
    printZeros = opts.printZeros
    return opts

def loadSqantiPaCsv(sqantiPaCsv):
    paMatrixDf = pd.read_csv(sqantiPaCsv)
    paMatrixDf.set_index('TAGS', inplace=True)
    paMatrixDf['numPipelines'] = paMatrixDf[getPipelineColumns(paMatrixDf)].sum(axis=1)
    return paMatrixDf

def loadEvalTsv(evalTsv):
    evalDf = pd.read_table(evalTsv)
    transDf = filterToTranscript(evalDf)
    return transDf

def getPipelineColumns(paMatrixDf):
    # wtc11 has pipeline1,pipeline2, ...
    # manatee has illumina1,ONT1,ONT2,...,PB1,PB2,..
    cols = [c for c in paMatrixDf.columns if c.startswith("pipeline")]
    if len(cols) == 0:
        cols = [c for c in paMatrixDf.columns if c.startswith("ONT") or c.startswith("PB")]
    if len(cols) == 0:
        raise Exception("no pipeline columns found")
    return cols

def countPipelinePredictions(matrixDf):
    predictedByCnt = defaultdict(int)
    for idx, row in matrixDf.iterrows():
        predictedByCnt[row.numPipelines] += 1
    return predictedByCnt

def writePredictionHisto(histoFh, label, subsetLabel, pipelineCnt, matrixDf):
    predictedByCnt = countPipelinePredictions(matrixDf)
    total = sum(predictedByCnt.values())
    cumulativeByCnt = 0
    for cnt in range(1, pipelineCnt + 1):
        if printZeros or (predictedByCnt[cnt] > 0):
            cumulativeByCnt += predictedByCnt[cnt]
            fileOps.prRowv(histoFh, label, subsetLabel, cnt,
                           predictedByCnt[cnt], rateFmt(predictedByCnt[cnt], total),
                           cumulativeByCnt, rateFmt(cumulativeByCnt, total))

def writePredictionStats(statsFh, label, subsetLabel, pipelineCnt, matrixDf):
    predictedCnts = matrixDf[getPipelineColumns(matrixDf)].sum(axis=1)
    if printZeros or (len(predictedCnts) > 0):
        meanPipelineCnt = predictedCnts.mean()
        medianPipelienCnt = predictedCnts.median()
        fileOps.prRowv(statsFh, label, subsetLabel, len(matrixDf),
                       round(meanPipelineCnt, 3), rateFmt(meanPipelineCnt, pipelineCnt),
                       round(medianPipelienCnt, 3), rateFmt(medianPipelienCnt, pipelineCnt))

def writePredictions(histoFh, statsFh, label, subsetLabel, pipelineCnt, matrixDf, filterDf=None):
    if filterDf is not None:
        matrixDf = matrixDf[matrixDf.structural_category.isin(filterDf.structural_category)]
    writePredictionHisto(histoFh, label, subsetLabel, pipelineCnt, matrixDf)
    writePredictionStats(statsFh, label, subsetLabel, pipelineCnt, matrixDf)

def fullSetReport(paMatrixDf, histoFh, statsFh):
    pipelineCnt = len(getPipelineColumns(paMatrixDf))
    knownDf, novelDf, ismDf, otherDf = splitBySqantiCategory(paMatrixDf)
    for subsetLabel, filterDf in (("all", None), ("known", knownDf), ("novel", novelDf), ("ism", ismDf), ("other", otherDf)):
        writePredictions(histoFh, statsFh, "all", subsetLabel, pipelineCnt, paMatrixDf, filterDf)

def evalPipelineReport(evaledMatrixDf, evalPipelineCntFh):
    fileOps.prRowv(evalPipelineCntFh, "gene", "transcript", "structural_category", "category", "numPipelines")

    for idx, row in evaledMatrixDf.iterrows():
        fileOps.prRowv(evalPipelineCntFh, row.gene, row.transcript, row.structural_category,
                       row.category, row.numPipelines)


def rtprcReport(paMatrixDf, transDf, idUjcMap, histoFh, statsFh, evalPipelineCntFh):
    pipelineCnt = len(getPipelineColumns(paMatrixDf))
    knownDf, novelDf, ismDf, otherDf = splitBySqantiCategory(paMatrixDf)
    transUjcDf = pd.merge(transDf, idUjcMap, on="transcript")
    evaledMatrixDf = pd.merge(paMatrixDf, transUjcDf, left_on="TAGS", right_on="LRGASP_id")
    addStructuralCategory(evaledMatrixDf)
    supportedMatrixDf, unsupportedMatrixDf = splitBySupport(evaledMatrixDf)

    for label, filterDf in (("evaled", None), ("known", knownDf), ("novel", novelDf), ("ism", ismDf)):
        writePredictions(histoFh, statsFh, label, "all", pipelineCnt, evaledMatrixDf, filterDf)
        writePredictions(histoFh, statsFh, label, "supported", pipelineCnt, supportedMatrixDf, filterDf)
        writePredictions(histoFh, statsFh, label, "unsupported", pipelineCnt, unsupportedMatrixDf, filterDf)

    if evalPipelineCntFh is not None:
        evalPipelineReport(evaledMatrixDf, evalPipelineCntFh)

def report(paMatrixDf, transDf, idUjcMap, histoFh, statsFh, evalPipelineCntFh):
    fileOps.prRowv(histoFh, "set", "subset", "pipelineCnts", "transcripts", "rate",
                   "cumulativeCnt", "cumulativeRate")
    fileOps.prRowv(statsFh, "set", "subset", "transcripts", "meanPipeline", "meanPipelineRate", "medianPipeline", "medianPipelineRate")

    fullSetReport(paMatrixDf, histoFh, statsFh)
    if transDf is not None:
        rtprcReport(paMatrixDf, transDf, idUjcMap, histoFh, statsFh, evalPipelineCntFh)

def sqantiSummary(sqantiPaCsv, evalTsv, idUjcMapTsv, histoTsv, statsTsv, evalPipelineCntTsv):
    paMatrixDf = loadSqantiPaCsv(sqantiPaCsv)

    transDf = loadEvalTsv(evalTsv) if evalTsv is not None else None
    idUjcMap = pd.read_table(idUjcMapTsv) if idUjcMapTsv is not None else None

    evalPipelineCntFh = open(evalPipelineCntTsv, 'w') if evalPipelineCntTsv is not None else None

    with open(histoTsv, 'w') as histoFh:
        with open(statsTsv, 'w') as statsFh:
            report(paMatrixDf, transDf, idUjcMap, histoFh, statsFh, evalPipelineCntFh)

def main(opts):
    sqantiSummary(opts.sqantiPaCsv, opts.evalTsv, opts.idUjcMapTsv, opts.histoTsv, opts.statsTsv,
                  opts.evalPipelineCntTsv)

main(parseArgs())
