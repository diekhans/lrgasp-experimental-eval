#!/usr/bin/env python3

import argparse
import pandas as pd
from pycbio.sys import fileOps


def parseArgs():
    desc = """pull stats for paper from eval spreadsheet tsv, add joinAnnotSummary added consolidate information"""
    parser = argparse.ArgumentParser(description=desc)
    parser.add_argument("evalTsv")
    parser.add_argument("statsTsv")
    return parser.parse_args()

def percent(n, total):
    if total == 0:
        return 0.0
    else:
        return round(100 * (n / total), 1)

def gencodeReport(evalDf, fh):
    # pb row is first with gencode and category
    df = evalDf[(evalDf.plat == "pb")]
    knownDf = df[(df.gencode == "known")]
    novelDf = df[(df.gencode == "novel")]
    rejectedDf = df[(df.gencode == "rejected")]

    # GENCODE-known, N=XX:
    fileOps.prRowv(fh, "gencodeKnown", len(knownDf))

    # GENCODE-novel, N=XX:,
    fileOps.prRowv(fh, "gencodeNovel", len(novelDf))

    # GENCODE-suspect, N=XX:
    fileOps.prRowv(fh, "gencodeRejected", len(rejectedDf))

    total = len(knownDf) + len(novelDf) + len(rejectedDf)

    # GENCODE-known validation rate, XX%
    fileOps.prRowv(fh, "gencodeKnowSupportRate",
                   percent(len(knownDf[knownDf.category != "unsupported"]),
                           len(knownDf)))

    # GENCODE-known that failed to validate n+XX
    fileOps.prRowv(fh, "gencodeKnowNotValidated",
                   percent(len(knownDf[knownDf.category == "unsupported"]),
                           len(knownDf)))

    # GENCODE-novel   validation rate, XX %
    fileOps.prRowv(fh, "gencodeNoverlSupportRate",
                   percent(len(novelDf[novelDf.category == "supported"]),
                           len(novelDf)))

    # GENCODE-suspect validation rate of XX,
    fileOps.prRowv(fh, "gencodeRejectedSupportRate",
                   percent(len(rejectedDf[rejectedDf.category == "supported"]),
                           len(rejectedDf)))

    # GENCODE-suspect “validated” XX
    fileOps.prRowv(fh, "gencodeRejectedSupport",
                   len(rejectedDf[rejectedDf.category == "supported"]))

_supportRanks = {
    "supported": 1,
    "likely": 2,
    "unsupported": 3,
    "": 4
}

def squantiEval(evalsDf, fh):
    # pb is first line of experiment experiment, other stats are NaN if not squanti-evaluated
    df = evalsDf[(evalsDf.plat == "pb")].dropna(subset=("capTrapPrepCount",))

    # convert category to key
    transDf = df.copy()
    transDf.insert(0, "rank", transDf.category.apply(lambda c: _supportRanks[c]))
    transDf.sort_values(["transcript", "rank"], inplace=True)
    transDf.drop_duplicates("transcript", inplace=True)

    # pull out highest
    novelDf = transDf[transDf.transcript.str.startswith('N')]

    pc = novelDf.loc[:, ["longOnlyCatCount", "longShortCatCount", "freeStyleCatCount"]].sum(axis = 1).copy()
    novelDf.insert(len(novelDf.columns), 'pipeLineCount', pc)

    # overview
    fileOps.prRowv(fh, "targets", len(set(evalsDf.target)))
    fileOps.prRowv(fh, "transcripts", len(set(evalsDf.transcript)))


    # novel isoforms count:
    fileOps.prRowv(fh, "novelIsoforms", len(novelDf))

    # novel isoforms detected in N pipelines (different cuttons)
    # novel isoforms in less name N pipelines
    maxNp = int(novelDf.pipeLineCount.max())
    fileOps.prRowv(fh, "maxPipelines", maxNp)

    # split number of transcripts into at last 1/4

    for np in range(1, maxNp + 1, maxNp // 4):
        fileOps.prRowv(fh, "novelPipelineCnt_ge_" + str(np), len(novelDf[novelDf.pipeLineCount >= np]))
        fileOps.prRowv(fh, "novelPipelineCnt_lt_" + str(np), len(novelDf[novelDf.pipeLineCount < np]))


def report(evalsDf, fh):
    fileOps.prRowv(fh, "name", "value")
    if 'gencode' in evalsDf.columns:
        gencodeReport(evalsDf, fh)
    squantiEval(evalsDf, fh)


def paperEvalStats(evalTsv, statsTsv):
    evalsDf = pd.read_table(evalTsv)
    with open(statsTsv, 'w') as fh:
        report(evalsDf, fh)

def main(opts):
    paperEvalStats(opts.evalTsv, opts.statsTsv)

main(parseArgs())
